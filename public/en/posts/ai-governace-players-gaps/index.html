<!doctype html><html lang=en dir=ltr><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Navigating the AI Governance Landscape: The Players and the Missing Pieces | Orn Smith's Blog</title>
<meta name=keywords content="AI,AI Governance"><meta name=description content="Over the past 5-6 months, I’ve been diving deep into the world of AI alignment and governance. Given my background as a go-to-market practitioner and my interest in advocacy, I’m particularly fascinated by how this field is becoming more accessible, especially within the private sector. This article is my wrap-up of the research I’ve done so far, along with some thoughts on where the gaps lie in the current AI governance landscape."><meta name=author content="Orn"><link rel=canonical href=http://localhost:1313/en/posts/ai-governace-players-gaps/><link crossorigin=anonymous href=/assets/css/stylesheet.84725a7d7c13fc6d140d352465c92e67b8d3d4e9906e7f4fa9bc9cbbb2843e22.css integrity="sha256-hHJafXwT/G0UDTUkZckuZ7jT1OmQbn9Pqbycu7KEPiI=" rel="preload stylesheet" as=style><link rel=icon href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=http://localhost:1313/en/posts/ai-governace-players-gaps/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><meta property="og:title" content="Navigating the AI Governance Landscape: The Players and the Missing Pieces"><meta property="og:description" content="Over the past 5-6 months, I’ve been diving deep into the world of AI alignment and governance. Given my background as a go-to-market practitioner and my interest in advocacy, I’m particularly fascinated by how this field is becoming more accessible, especially within the private sector. This article is my wrap-up of the research I’ve done so far, along with some thoughts on where the gaps lie in the current AI governance landscape."><meta property="og:type" content="article"><meta property="og:url" content="http://localhost:1313/en/posts/ai-governace-players-gaps/"><meta property="og:image" content="http://localhost:1313/img/ai-governance-players-blog-cover.png"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-09-27T00:00:00+00:00"><meta property="article:modified_time" content="2024-09-27T00:00:00+00:00"><meta property="og:site_name" content="Orn Smith's Blog"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="http://localhost:1313/img/ai-governance-players-blog-cover.png"><meta name=twitter:title content="Navigating the AI Governance Landscape: The Players and the Missing Pieces"><meta name=twitter:description content="Over the past 5-6 months, I’ve been diving deep into the world of AI alignment and governance. Given my background as a go-to-market practitioner and my interest in advocacy, I’m particularly fascinated by how this field is becoming more accessible, especially within the private sector. This article is my wrap-up of the research I’ve done so far, along with some thoughts on where the gaps lie in the current AI governance landscape."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"http://localhost:1313/en/posts/"},{"@type":"ListItem","position":2,"name":"Navigating the AI Governance Landscape: The Players and the Missing Pieces","item":"http://localhost:1313/en/posts/ai-governace-players-gaps/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Navigating the AI Governance Landscape: The Players and the Missing Pieces","name":"Navigating the AI Governance Landscape: The Players and the Missing Pieces","description":"Over the past 5-6 months, I’ve been diving deep into the world of AI alignment and governance. Given my background as a go-to-market practitioner and my interest in advocacy, I’m particularly fascinated by how this field is becoming more accessible, especially within the private sector. This article is my wrap-up of the research I’ve done so far, along with some thoughts on where the gaps lie in the current AI governance landscape.","keywords":["AI","AI Governance"],"articleBody":" Over the past 5-6 months, I’ve been diving deep into the world of AI alignment and governance. Given my background as a go-to-market practitioner and my interest in advocacy, I’m particularly fascinated by how this field is becoming more accessible, especially within the private sector. This article is my wrap-up of the research I’ve done so far, along with some thoughts on where the gaps lie in the current AI governance landscape.\nIf you’re short on time, here’s a quick summary:\nExecutive Summary (TLDR) The AI governance landscape is evolving, with firms offering services to help organizations comply with regulations like the EU AI Act. These providers include management consulting firms, tech consulting firms, law firms, and specialized AI safety firms, all offering risk management services—although many descriptions are vague. While compliance is crucial, most firms focus on short-term risk evaluation, neglecting broader AI safety and alignment challenges, such as preventing misuse of AI and managing economic impacts. Emerging countries importing AI technologies face unique challenges in auditing these opaque, large-scale systems, making it essential to invest in local AI safety expertise. AI governance should address long-term safety and alignment issues, not just compliance, to ensure that AI benefits everyone, including smaller nations. The Different Types of AI Governance Providers There’s a wide variety of AI governance providers, generally falling into four categories:\nManagement consulting firms – Trusted by large organizations, these firms offer broad, high-level strategic advice, including AI governance. Technology consulting firms – Similar to management consultants but with a technical focus, they help companies integrate AI while staying compliant with regulations. Law firms – With growing AI regulations, law firms guide companies through legal compliance, focusing on frameworks like the EU AI Act and data privacy laws (e.g., GDPR). Specialized AI safety firms – Newer, niche players that focus specifically on AI risks and safety, offering services like AI red teaming and model audits. For curious minds, I’ve listed a few examples below. Feel free to visit their websites to see how they talk about their services in Responsible AI, AI Ethics, AI Governance, or AI Safety (terms that are often used interchangeably):\nManagement consulting: Bain, PwC, McKinsey, Deloitte, Forrester Tech consulting: Accenture, IBM Law firms: Gibson Dunn \u0026 Crutcher, DLA Piper, Clifford Chance, Manatt Phelps \u0026 Phillips Emerging specialized AI firms: Luminos.Law, Babl.ai The Rise of Platforms to Democratize AI Governance Initially, I was concerned that there might be no solution to make AI governance more accessible. Smaller companies or startups, lacking the resources to engage with these firms, seemed to be left out of the conversation. This worried me because AI safety isn’t just a concern for large organizations—it affects everyone.\nFortunately, in addition to these service providers, a growing market for AI governance platforms is emerging. These are software tools that help companies automate and track their AI compliance efforts, making governance more accessible. For example, Fairly.ai specifically mentions use cases for small and medium-sized businesses (SMBs) and startups.\nHere are some platforms to check out:\nBuildaligned.ai Credo.ai enz.ai Fairly.ai getalignai.com Holisticai.com Luminos.ai Monitaur.ai A Common Problem: Vague Descriptions While I originally plan to analyze their services, one thing that surprised me in my research is how vague these firms are about what they actually offer. Many websites and materials don’t clearly explain their services in details, making it hard to figure out what sets them apart or how their services actually work.\nTake risk management, for example. Almost every firm lists it as a service, but what does that really mean? Most providers evaluate risks around privacy, bias, or safety, using compliance frameworks like the EU AI Act as their guide. In many cases, it feels like companies are simply checking regulatory boxes.\nThe Differences: Specialized AI Safety Firms and Platforms Specialized AI safety firms tend to stand out more, offering clearer and more focused services. For instance, they might use terms like “AI red teaming” (where they stress-test AI models to expose vulnerabilities) or model audits (to evaluate fairness and safety).\nHowever, even with this extra clarity, I still think there’s room for improvement. If you’re not already well-versed in AI safety, it can be hard to differentiate these firms from one another. I’d love to see more transparency—more concrete examples of how they’ve helped businesses and a clearer picture of their day-to-day services.\nThe Bigger Picture: AI Safety and Alignment While compliance and risk management are important, they’re only part of what AI governance should be about. In an AI Alignment course by BlueDot I enrolled, we discussed how critical it is to ensure that AI systems align with human values and goals—not just meet legal requirements. And that’s the gap I see in this market.\nMost AI governance services focus on short-term compliance issues, like making sure your AI doesn’t break the law. But the bigger, more complex problems—like preventing misuse of powerful AI by bad actors or ensuring industry-wide coordination to avoid an AI arms race—aren’t being addressed.\nThe Importance of AI Safety Audits for Emerging Countries This issue is especially critical for emerging countries that import AI technologies. These nations often lack the local expertise or resources to fully understand the risks associated with AI systems from large global tech companies. The opaque nature of these AI products makes it even more important for these countries to invest in AI safety audits.\nSuch audits help local experts understand how these systems operate and whether they’re safe. Without this knowledge, countries risk adopting technologies they can’t fully control, which could lead to unintended consequences—especially when these technologies touch on national security or large-scale business operations.\nGovernance providers should help emerging countries build their own capacity to conduct these audits. Otherwise, they’re left vulnerable to decisions made by bigger players, putting critical infrastructure at risk.\nWhat I’ve Learned (and What We Can Do) Through my course on AI Alignment, I’ve learned that “alignment” goes beyond just safety. It’s about making sure AI systems reflect human values. And achieving this is much harder than it sounds. The current focus on compliance is important, but we need to think beyond that. How do we make sure AI systems are actually doing what we want? How do we ensure that AI benefits everyone, not just a select few?\nI’m still learning, but what I do know is that the current state of AI governance is only scratching the surface. There’s a lot more we could be doing, especially to solve the biggest challenges facing AI safety.\nFinal Thoughts AI governance providers, policymakers, and the industry as a whole need to take a step back and think bigger. Compliance is crucial, but it’s not the end goal. We need to address the long-term challenges of AI safety and alignment, ensuring that AI is trustworthy and beneficial for everyone.\nThis is particularly important for smaller or emerging countries. They need to build their own capacity for AI audits to understand the risks they’re facing. Without this, they’re left dependent on technologies they can’t fully control.\nI’d love to see more companies and governance providers step up to fill these gaps. It’s not easy, but it’s work worth doing. AI is transforming our world, and we need to make sure it’s headed in the right direction.\nDisclaimer: I’m not an expert (yet) in this field, and it’s evolving fast. If there’s anything I’ve missed, feel free to let me know!\nThanks: Aaron Scher and Chris Esposo for their feedback on my earlier drafts.\n","wordCount":"1247","inLanguage":"en","image":"http://localhost:1313/img/ai-governance-players-blog-cover.png","datePublished":"2024-09-27T00:00:00Z","dateModified":"2024-09-27T00:00:00Z","author":{"@type":"Person","name":"Orn"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:1313/en/posts/ai-governace-players-gaps/"},"publisher":{"@type":"Organization","name":"Orn Smith's Blog","logo":{"@type":"ImageObject","url":"http://localhost:1313/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><noscript><iframe src="//www.googletagmanager.com/ns.html?id=GTM-KMD62ZP" height=0 width=0 style=display:none;visibility:hidden></iframe></noscript><script>localStorage.getItem("pref-theme")==="dark"&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=http://localhost:1313/en/ accesskey=h title="ornsmith.com (Alt + H)"><img src=http://localhost:1313/apple-touch-icon.png alt aria-label=logo height=35>ornsmith.com</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li><li><a href=http://localhost:1313/th/ title=Thai aria-label=Thai>Th</a></li></ul></div></div><ul id=menu><li><a href=http://localhost:1313/en/portfolio/overview title=Works><span>Works</span></a></li><li><a href=http://localhost:1313/en/blog title=Blog><span>Blog</span></a></li><li><a href=http://localhost:1313/en/about/ title=About><span>About</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">Navigating the AI Governance Landscape: The Players and the Missing Pieces</h1><div class=post-meta><span title='2024-09-27 00:00:00 +0000 UTC'>27 September 2024</span>&nbsp;·&nbsp;6 min&nbsp;·&nbsp;1247 words&nbsp;·&nbsp;Orn</div></header><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#executive-summary-tldr>Executive Summary (TLDR)</a></li><li><a href=#the-different-types-of-ai-governance-providers>The Different Types of AI Governance Providers</a></li><li><a href=#the-rise-of-platforms-to-democratize-ai-governance>The Rise of Platforms to Democratize AI Governance</a><ul><li><a href=#a-common-problem-vague-descriptions>A Common Problem: Vague Descriptions</a></li><li><a href=#the-differences-specialized-ai-safety-firms-and-platforms>The Differences: Specialized AI Safety Firms and Platforms</a></li></ul></li><li><a href=#the-bigger-picture-ai-safety-and-alignment>The Bigger Picture: AI Safety and Alignment</a></li><li><a href=#the-importance-of-ai-safety-audits-for-emerging-countries>The Importance of AI Safety Audits for Emerging Countries</a></li><li><a href=#what-ive-learned-and-what-we-can-do>What I’ve Learned (and What We Can Do)</a></li><li><a href=#final-thoughts>Final Thoughts</a></li></ul></nav></div></details></div><div class=post-content><figure class=align-center><img loading=lazy src=/img/ai-governance-players-blog-cover.png#center></figure><p>Over the past 5-6 months, I’ve been diving deep into the world of AI alignment and governance. Given my background as a go-to-market practitioner and my interest in advocacy, I’m particularly fascinated by how this field is becoming more accessible, especially within the private sector. This article is my wrap-up of the research I’ve done so far, along with some thoughts on where the gaps lie in the current AI governance landscape.</p><p>If you’re short on time, here’s a quick summary:</p><h2 id=executive-summary-tldr>Executive Summary (TLDR)<a hidden class=anchor aria-hidden=true href=#executive-summary-tldr>#</a></h2><ul><li>The AI governance landscape is evolving, with firms offering services to help organizations comply with regulations like the EU AI Act.</li><li>These providers include management consulting firms, tech consulting firms, law firms, and specialized AI safety firms, all offering risk management services—although many descriptions are vague.</li><li>While compliance is crucial, most firms focus on short-term risk evaluation, neglecting broader AI safety and alignment challenges, such as preventing misuse of AI and managing economic impacts.</li><li>Emerging countries importing AI technologies face unique challenges in auditing these opaque, large-scale systems, making it essential to invest in local AI safety expertise.</li><li>AI governance should address long-term safety and alignment issues, not just compliance, to ensure that AI benefits everyone, including smaller nations.</li></ul><h2 id=the-different-types-of-ai-governance-providers>The Different Types of AI Governance Providers<a hidden class=anchor aria-hidden=true href=#the-different-types-of-ai-governance-providers>#</a></h2><p>There’s a wide variety of AI governance providers, generally falling into four categories:</p><ul><li><strong>Management consulting firms</strong> – Trusted by large organizations, these firms offer broad, high-level strategic advice, including AI governance.</li><li><strong>Technology consulting firms</strong> – Similar to management consultants but with a technical focus, they help companies integrate AI while staying compliant with regulations.</li><li><strong>Law firms</strong> – With growing AI regulations, law firms guide companies through legal compliance, focusing on frameworks like the EU AI Act and data privacy laws (e.g., GDPR).</li><li><strong>Specialized AI safety firms</strong> – Newer, niche players that focus specifically on AI risks and safety, offering services like AI red teaming and model audits.</li></ul><p>For curious minds, I’ve listed a few examples below. Feel free to visit their websites to see how they talk about their services in Responsible AI, AI Ethics, AI Governance, or AI Safety (terms that are often used interchangeably):</p><ul><li><strong>Management consulting</strong>: Bain, PwC, McKinsey, Deloitte, Forrester</li><li><strong>Tech consulting</strong>: Accenture, IBM</li><li><strong>Law firms</strong>: Gibson Dunn & Crutcher, DLA Piper, Clifford Chance, Manatt Phelps & Phillips</li><li><strong>Emerging specialized AI firms</strong>: Luminos.Law, Babl.ai</li></ul><h2 id=the-rise-of-platforms-to-democratize-ai-governance>The Rise of Platforms to Democratize AI Governance<a hidden class=anchor aria-hidden=true href=#the-rise-of-platforms-to-democratize-ai-governance>#</a></h2><p>Initially, I was concerned that there might be no solution to make AI governance more accessible. Smaller companies or startups, lacking the resources to engage with these firms, seemed to be left out of the conversation. This worried me because AI safety isn’t just a concern for large organizations—it affects everyone.</p><p>Fortunately, in addition to these service providers, a growing market for AI governance platforms is emerging. These are software tools that help companies automate and track their AI compliance efforts, making governance more accessible. For example, Fairly.ai specifically mentions use cases for small and medium-sized businesses (SMBs) and startups.</p><p>Here are some platforms to check out:</p><ul><li>Buildaligned.ai</li><li>Credo.ai</li><li>enz.ai</li><li>Fairly.ai</li><li>getalignai.com</li><li>Holisticai.com</li><li>Luminos.ai</li><li>Monitaur.ai</li></ul><h3 id=a-common-problem-vague-descriptions>A Common Problem: Vague Descriptions<a hidden class=anchor aria-hidden=true href=#a-common-problem-vague-descriptions>#</a></h3><p>While I originally plan to analyze their services, one thing that surprised me in my research is how vague these firms are about what they actually offer. Many websites and materials don’t clearly explain their services in details, making it hard to figure out what sets them apart or how their services actually work.</p><p>Take risk management, for example. Almost every firm lists it as a service, but what does that really mean? Most providers evaluate risks around privacy, bias, or safety, using compliance frameworks like the EU AI Act as their guide. In many cases, it feels like companies are simply checking regulatory boxes.</p><h3 id=the-differences-specialized-ai-safety-firms-and-platforms>The Differences: Specialized AI Safety Firms and Platforms<a hidden class=anchor aria-hidden=true href=#the-differences-specialized-ai-safety-firms-and-platforms>#</a></h3><p>Specialized AI safety firms tend to stand out more, offering clearer and more focused services. For instance, they might use terms like “AI red teaming” (where they stress-test AI models to expose vulnerabilities) or model audits (to evaluate fairness and safety).</p><p>However, even with this extra clarity, I still think there’s room for improvement. If you’re not already well-versed in AI safety, it can be hard to differentiate these firms from one another. I’d love to see more transparency—more concrete examples of how they’ve helped businesses and a clearer picture of their day-to-day services.</p><h2 id=the-bigger-picture-ai-safety-and-alignment>The Bigger Picture: AI Safety and Alignment<a hidden class=anchor aria-hidden=true href=#the-bigger-picture-ai-safety-and-alignment>#</a></h2><p>While compliance and risk management are important, they’re only part of what AI governance should be about. In an AI Alignment course by BlueDot I enrolled, we discussed how critical it is to ensure that AI systems align with human values and goals—not just meet legal requirements. And that’s the gap I see in this market.</p><p>Most AI governance services focus on short-term compliance issues, like making sure your AI doesn’t break the law. But the bigger, more complex problems—like preventing misuse of powerful AI by bad actors or ensuring industry-wide coordination to avoid an AI arms race—aren’t being addressed.</p><h2 id=the-importance-of-ai-safety-audits-for-emerging-countries>The Importance of AI Safety Audits for Emerging Countries<a hidden class=anchor aria-hidden=true href=#the-importance-of-ai-safety-audits-for-emerging-countries>#</a></h2><p>This issue is especially critical for <strong>emerging countries</strong> that import AI technologies. These nations often lack the local expertise or resources to fully understand the risks associated with AI systems from large global tech companies. The opaque nature of these AI products makes it even more important for these countries to invest in AI safety audits.</p><p>Such audits help local experts understand how these systems operate and whether they’re safe. Without this knowledge, countries risk adopting technologies they can’t fully control, which could lead to unintended consequences—especially when these technologies touch on national security or large-scale business operations.</p><p>Governance providers should help emerging countries build their own capacity to conduct these audits. Otherwise, they’re left vulnerable to decisions made by bigger players, putting critical infrastructure at risk.</p><h2 id=what-ive-learned-and-what-we-can-do>What I’ve Learned (and What We Can Do)<a hidden class=anchor aria-hidden=true href=#what-ive-learned-and-what-we-can-do>#</a></h2><p>Through my course on AI Alignment, I’ve learned that <strong>“alignment”</strong> goes beyond just safety. It’s about making sure AI systems reflect human values. And achieving this is much harder than it sounds. The current focus on compliance is important, but we need to think beyond that. How do we make sure AI systems are actually doing what we want? How do we ensure that AI benefits everyone, not just a select few?</p><p>I’m still learning, but what I do know is that the current state of AI governance is only scratching the surface. There’s a lot more we could be doing, especially to solve the biggest challenges facing AI safety.</p><h2 id=final-thoughts>Final Thoughts<a hidden class=anchor aria-hidden=true href=#final-thoughts>#</a></h2><p>AI governance providers, policymakers, and the industry as a whole need to take a step back and think bigger. Compliance is crucial, but it’s not the end goal. We need to address the long-term challenges of AI safety and alignment, ensuring that AI is trustworthy and beneficial for everyone.</p><p>This is particularly important for smaller or emerging countries. They need to build their own capacity for AI audits to understand the risks they’re facing. Without this, they’re left dependent on technologies they can’t fully control.</p><p>I’d love to see more companies and governance providers step up to fill these gaps. It’s not easy, but it’s work worth doing. AI is transforming our world, and we need to make sure it’s headed in the right direction.</p><hr><p><strong>Disclaimer:</strong> I’m not an expert (yet) in this field, and it’s evolving fast. If there’s anything I’ve missed, feel free to let me know!</p><p><strong>Thanks:</strong> Aaron Scher and Chris Esposo for their feedback on my earlier drafts.</p></div><footer class=post-footer><ul class=post-tags><li><a href=http://localhost:1313/en/tags/ai/>AI</a></li><li><a href=http://localhost:1313/en/tags/ai-governance/>AI Governance</a></li></ul><nav class=paginav><a class=next href=http://localhost:1313/en/posts/welcome/><span class=title>Next »</span><br><span>Welcome!</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share Navigating the AI Governance Landscape: The Players and the Missing Pieces on x" href="https://x.com/intent/tweet/?text=Navigating%20the%20AI%20Governance%20Landscape%3a%20The%20Players%20and%20the%20Missing%20Pieces&amp;url=http%3a%2f%2flocalhost%3a1313%2fen%2fposts%2fai-governace-players-gaps%2f&amp;hashtags=AI%2cAIGovernance"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Navigating the AI Governance Landscape: The Players and the Missing Pieces on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=http%3a%2f%2flocalhost%3a1313%2fen%2fposts%2fai-governace-players-gaps%2f&amp;title=Navigating%20the%20AI%20Governance%20Landscape%3a%20The%20Players%20and%20the%20Missing%20Pieces&amp;summary=Navigating%20the%20AI%20Governance%20Landscape%3a%20The%20Players%20and%20the%20Missing%20Pieces&amp;source=http%3a%2f%2flocalhost%3a1313%2fen%2fposts%2fai-governace-players-gaps%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Navigating the AI Governance Landscape: The Players and the Missing Pieces on facebook" href="https://facebook.com/sharer/sharer.php?u=http%3a%2f%2flocalhost%3a1313%2fen%2fposts%2fai-governace-players-gaps%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Navigating the AI Governance Landscape: The Players and the Missing Pieces on whatsapp" href="https://api.whatsapp.com/send?text=Navigating%20the%20AI%20Governance%20Landscape%3a%20The%20Players%20and%20the%20Missing%20Pieces%20-%20http%3a%2f%2flocalhost%3a1313%2fen%2fposts%2fai-governace-players-gaps%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=http://localhost:1313/en/>Orn Smith's Blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>